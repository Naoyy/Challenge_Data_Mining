{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data + Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder, RobustScaler, PolynomialFeatures, TargetEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "import joblib\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train= pd.read_csv(\"data/train.csv\",sep=\",\",low_memory=False)\n",
    "data_test = pd.read_csv(\"data/test.csv\",sep=\",\",low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération d'observations\n",
    "\n",
    "Lorsque la voiture est électrique: on peut se permettre de set `ec(cm3)`, `Fuel consumption `, `z (Wh/km)` à 0\n",
    "\n",
    "lorsque la voiture n'est pas hybride / électrique : on peut mettre `Electric range (km)` à 0\n",
    "\n",
    "A voir si on choisir de prendre le traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete columns\n",
    "\n",
    "Supprimer les colonnes avec 1 seul valeur unique (aucune info) ou 0 valeur unique (que des NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colonne supprimée: MMS\n",
      "colonne supprimée: r\n",
      "colonne supprimée: Ernedc (g/km)\n",
      "colonne supprimée: De\n",
      "colonne supprimée: Vf\n",
      "colonne supprimée: Status\n"
     ]
    }
   ],
   "source": [
    "valeurs_uniques = {}\n",
    "nombre_val_unique={}\n",
    "for col in data_train.columns:\n",
    "    valeurs_uniques[col]=data_train[col].unique().tolist()\n",
    "    nombre_val_unique[col]=data_train[col].nunique()\n",
    "\n",
    "for element in nombre_val_unique:\n",
    "    if nombre_val_unique[element]<=1:\n",
    "        print(f\"colonne supprimée: {element}\")\n",
    "        data_train.drop(columns=element, inplace=True)\n",
    "        data_test.drop(columns=element, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer les colonnes avec + de 50% de NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colonne supprimée: Enedc (g/km)\n",
      "colonne supprimée: z (Wh/km)\n",
      "colonne supprimée: Electric range (km)\n"
     ]
    }
   ],
   "source": [
    "for col in data_train.columns:\n",
    "    if (data_train[col].isna().sum()/data_train.shape[0] > 0.5):\n",
    "        print(f\"colonne supprimée: {col}\")\n",
    "        data_train.drop(columns=col, inplace=True)\n",
    "        data_test.drop(columns=col, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer les `Date` et `ID` (seulement pour train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colonne supprimée pour data_train: Date of registration, ID\n",
      "colonne supprimée pour data_test: Date of registration\n"
     ]
    }
   ],
   "source": [
    "data_train.drop(columns=['Date of registration','ID'], inplace=True)\n",
    "data_test.drop(columns='Date of registration', inplace=True)\n",
    "\n",
    "print(f\"colonne supprimée pour data_train: Date of registration, ID\")\n",
    "print(f\"colonne supprimée pour data_test: Date of registration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_categoricals = data_test.select_dtypes(include=\"object\").columns.tolist()\n",
    "col_numericals = [col for col in data_test.columns if col not in col_categoricals]\n",
    "col_numericals.remove(\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers \n",
    "\n",
    "Utilisation de l'écart interquartile pour identifier les valeurs aberrantes.\n",
    "\n",
    "Imputation des outliers:\n",
    "\n",
    "Fixer les valeurs aberrantes à un certain pourcentage (par exemple, 5e et 95e percentiles).\n",
    "\n",
    "**on pourrait aussi tenter d'imputer par la médiane si cela n'aboutit pas** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_outliers(data, column_name, lower_percentile=5, upper_percentile=95):\n",
    "    \"\"\"\n",
    "    Detects and imputes outliers using winsorizing for a specific column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data: Pandas DataFrame, input data\n",
    "    - column_name: str, name of the column to be winsorized\n",
    "    - lower_percentile: int, lower percentile for winsorizing (default: 5)\n",
    "    - upper_percentile: int, upper percentile for winsorizing (default: 95)\n",
    "\n",
    "    Returns:\n",
    "    - winsorized_data: Pandas DataFrame, data with outliers winsorized for the specified column\n",
    "    \"\"\"\n",
    "\n",
    "    column_data = data[column_name]\n",
    "\n",
    "    q1 = np.percentile(column_data, lower_percentile)\n",
    "    q3 = np.percentile(column_data, upper_percentile)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    data[column_name] = np.clip(column_data, lower_bound, upper_bound)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_numericals:\n",
    "    data_train=winsorize_outliers(data_train,col)\n",
    "    data_test=winsorize_outliers(data_test,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaN by median/mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputers={}\n",
    "_coefficient_variation= lambda series : series.std()/series.mean()\n",
    "\n",
    "def fill_missing_values(colname : str,data:pd.DataFrame) -> None:\n",
    "    \n",
    "    if data[colname].dtype in [\"float64\"]:\n",
    "        if _coefficient_variation(data[colname]) > 0.15 :\n",
    "            imputers[colname]=SimpleImputer(missing_values=np.nan,strategy=\"median\")\n",
    "        else:\n",
    "            imputers[colname]=SimpleImputer(missing_values=np.nan,strategy=\"mean\")\n",
    "    else:\n",
    "        imputers[colname]=SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    imputers[colname].fit(data[colname].to_numpy().reshape(-1,1))\n",
    "    pass\n",
    "\n",
    "for col in data_test.columns[1:]:\n",
    "    fill_missing_values(col,data_train)\n",
    "    data_train[col]=pd.Series(imputers[col].transform(data_train[col].to_numpy().reshape(-1,1)).flatten())\n",
    "    data_test[col]=pd.Series(imputers[col].transform(data_test[col].to_numpy().reshape(-1,1)).flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical columns\n",
    "\n",
    "Many choices:\n",
    "- Label/Ordinal encoding\n",
    "- Target encoding\n",
    "- Impact encoding\n",
    "\n",
    "\n",
    "Label/Ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders={}\n",
    "def ordinal_encoder(colname:str,data:pd.DataFrame,train=True):\n",
    "    if train:\n",
    "        encoders[colname]=OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "        data[colname]=encoders[colname].fit_transform(data[[colname]])\n",
    "        pass\n",
    "    else:\n",
    "        data[colname]=encoders[colname].transform(data[[colname]])\n",
    "        pass\n",
    "\n",
    "for col in col_categoricals:\n",
    "    ordinal_encoder(col,data_train)\n",
    "    ordinal_encoder(col,data_test,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders={}\n",
    "def target_encoder(colname:str,data:pd.DataFrame,train=True):\n",
    "    if train:\n",
    "        encoders[colname]=TargetEncoder(target_type='continuous', smooth='auto',random_state=42)\n",
    "        data[colname]=encoders[colname].fit_transform(data[[colname]],data['Ewltp (g/km)'])\n",
    "        pass\n",
    "    else:\n",
    "        data[colname]=encoders[colname].transform(data[[colname]])\n",
    "        pass\n",
    "\n",
    "for col in col_categoricals:\n",
    "    target_encoder(col,data_train)\n",
    "    target_encoder(col,data_test,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact Encoding\n",
    "\n",
    "Proposé par Sam B. J'ai utilisé Chat GPT pour l'implémenter honnêtement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders={}\n",
    "def impact_encoder(colname:str,data:pd.DataFrame,train=True):\n",
    "    if train:\n",
    "        encoders[colname]=LeaveOneOutEncoder(handle_unknown=-1)\n",
    "        data[colname]=encoders[colname].fit_transform(data[[colname]],data['Ewltp (g/km)'])\n",
    "        pass\n",
    "    else:\n",
    "        data[colname]=encoders[colname].transform(data[[colname]])\n",
    "        pass\n",
    "\n",
    "for col in col_categoricals:\n",
    "    impact_encoder(col,data_train)\n",
    "    impact_encoder(col,data_test,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Doit-on utiliser ces variables ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conforme(df):\n",
    "    df['conforme'] = df['Tan'].isna()\n",
    "    df['conforme'] = df['conforme'].apply(lambda x: 1 if x==False else 0)\n",
    "    df.drop(columns='Tan', inplace=True)\n",
    "    pass\n",
    "def compute_surface(obs):\n",
    "    max_largeur= max(obs['At1 (mm)'], obs['At2 (mm)'])\n",
    "    return obs['W (mm)']*obs['At1 (mm)'] if max_largeur == obs['At1 (mm)'] else obs['W (mm)'] * obs['At2 (mm)']\n",
    "\n",
    "def create_surface(df):\n",
    "    df['surface']= df.apply(compute_surface, axis=1)\n",
    "    pass\n",
    "\n",
    "create_conforme(data_train)\n",
    "create_surface(data_train)\n",
    "\n",
    "create_conforme(data_test)\n",
    "create_surface(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_train, test_size=0.33, random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"Ewltp (g/km)\"]), train[\"Ewltp (g/km)\"]\n",
    "X_test, y_test = test.drop(columns=[\"Ewltp (g/km)\"]), test[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "\n",
    "Use all columns except those dropped (MMS, r, Ernedc (g/km), De,Vf,StatusEnedc (g/km),z (Wh/km),Electric range (km),Date of registration). \n",
    "\n",
    "ordinal encoding. Strandard fill NaN. Random forest. No feature Engineering.\n",
    "\n",
    "Computation time: 41min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 2.8986731992878796\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Ewltp (g/km)\"] = random_forest.predict(data_test.drop(columns='ID'))\n",
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"data/new_simple_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_simple_model.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(random_forest, 'models/random_forest_simple_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
