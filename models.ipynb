{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.preprocessing\n",
    "from src.preprocessing import Dataset,Preprocessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de la donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=Dataset(\"data/train.csv\")\n",
    "data_train=train.load_data()\n",
    "test=Dataset(\"data/test.csv\")\n",
    "data_test=test.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessor=Preprocessor(data_train,train=True)\n",
    "test_preprocessor=Preprocessor(data_test,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération d'observations\n",
    "\n",
    "Lorsque la voiture est électrique: on peut se permettre de set `ec(cm3)`, `Fuel consumption `, `z (Wh/km)` à 0\n",
    "\n",
    "lorsque la voiture n'est pas hybride / électrique : on peut mettre `Electric range (km)` à 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessor.recup_electric()\n",
    "test_preprocessor.recup_electric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete columns\n",
    "\n",
    "Supprimer les colonnes avec 1 seul valeur unique (aucune info) ou 0 valeur unique (que des NaN)\n",
    "\n",
    "Supprimer les colonnes avec **+ de 50%** de NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMS', 'r', 'Vf', 'Enedc (g/km)', 'De', 'Status', 'Ernedc (g/km)'] have been deleted on train data\n",
      "['MMS', 'r', 'Vf', 'Enedc (g/km)', 'De', 'Status', 'Ernedc (g/km)'] have been deleted on test data\n"
     ]
    }
   ],
   "source": [
    "train_preprocessor.delete_useless_columns()\n",
    "test_preprocessor.delete_useless_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers \n",
    "\n",
    "Utilisation de l'écart interquartile pour identifier les valeurs aberrantes.\n",
    "\n",
    "Imputation des outliers:\n",
    "\n",
    "Fixer les valeurs aberrantes à un certain pourcentage (par exemple, 5e et 95e percentiles).\n",
    "\n",
    "### windorization of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols=data_train.select_dtypes(include='number').columns.tolist()\n",
    "numerical_cols.remove('ID')\n",
    "numerical_cols.remove('Ewltp (g/km)')\n",
    "\n",
    "for col in numerical_cols:\n",
    "    train_preprocessor.winsorize_outliers(col)\n",
    "    test_preprocessor.winsorize_outliers(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaN by median/mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variables=list(filter(lambda x : x not in ['ID','Ewltp (g/km)','Date of registration'],data_train.columns.tolist()))\n",
    "\n",
    "for col in x_variables:\n",
    "    train_preprocessor.fill_missing_values(col)\n",
    "    test_preprocessor.fill_missing_values(col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customized encoding. \n",
    "\n",
    "- Count Encoder (nunique >=15)\n",
    "```\n",
    "Country 29  valeurs uniques\n",
    "VFN 8456  valeurs uniques\n",
    "Mh 95  valeurs uniques\n",
    "Man 104  valeurs uniques\n",
    "Tan 6318  valeurs uniques\n",
    "T 1506  valeurs uniques\n",
    "Va 5413  valeurs uniques\n",
    "Ve 25570  valeurs uniques\n",
    "Mk 694  valeurs uniques\n",
    "Cn 8323  valeurs uniques\n",
    "IT 487  valeurs uniques\n",
    "```\n",
    "- OHE Encoder (nunique < 15) rajoute 35 colonnes \n",
    "```\n",
    "Mp 10  valeurs uniques\n",
    "Ct 5  valeurs uniques\n",
    "Cr 3  valeurs uniques\n",
    "Ft 11  valeurs uniques\n",
    "Fm 6  valeurs uniques\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding count : Country\n",
      "encoding count : VFN\n",
      "encoding OHE : Mp\n",
      "encoding count : Mh\n",
      "encoding count : Man\n",
      "encoding count : Tan\n",
      "encoding count : T\n",
      "encoding count : Va\n",
      "encoding count : Ve\n",
      "encoding count : Mk\n",
      "encoding count : Cn\n",
      "encoding OHE : Ct\n",
      "encoding OHE : Cr\n",
      "encoding OHE : Ft\n",
      "encoding OHE : Fm\n",
      "encoding count : IT\n"
     ]
    }
   ],
   "source": [
    "col_categoricals=list(filter(lambda x: x not in numerical_cols,x_variables))\n",
    "\n",
    "for col in col_categoricals:\n",
    "    if Preprocessor.nombre_val_unique[col]>=15: \n",
    "        train_preprocessor.count_encoder(col)\n",
    "        test_preprocessor.count_encoder(col)\n",
    "        print(f\"encoding count : {col}\")\n",
    "    else:\n",
    "        train_preprocessor.ohe_encoder(col)\n",
    "        test_preprocessor.ohe_encoder(col)\n",
    "        print(f\"encoding OHE : {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(columns=['Date of registration','ID','Erwltp (g/km)'], inplace=True)\n",
    "data_test.drop(columns=['Date of registration','Erwltp (g/km)'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_train, test_size=0.33, random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"Ewltp (g/km)\"]), train[\"Ewltp (g/km)\"]\n",
    "X_test, y_test = test.drop(columns=[\"Ewltp (g/km)\"]), test[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':4000,\n",
    "          'max_depth': 35,\n",
    "          'learning_rate': 0.005,\n",
    "          'colsample_bytree':0.80,\n",
    "          'gamma':10,\n",
    "          'reg_alpha':0.8,\n",
    "          'reg_lambda':0.1,\n",
    "          'objective': 'reg:squarederror',\n",
    "          'tree_method': 'hist',\n",
    "          'n_jobs':-1\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor(**params)\n",
    "\n",
    "model.fit(data_train.drop(columns='Ewltp (g/km)'),data_train['Ewltp (g/km)'])\n",
    "\n",
    "data_test[\"Ewltp (g/km)\"] = model.predict(data_test.drop(columns=\"ID\"))\n",
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"results/new_final_xgb_no_erwltp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost k-fold = 15 (Modèle Challenger)\n",
    "\n",
    "approx time: 8hours\n",
    "\n",
    "computing time: 614min =10hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for this fold: 2.8137879227060356\n",
      "MAE for this fold: 2.807222170572855\n",
      "MAE for this fold: 2.8214681395667456\n",
      "MAE for this fold: 2.8266807353876753\n",
      "MAE for this fold: 2.8236043179970443\n",
      "MAE for this fold: 2.808979971720696\n",
      "MAE for this fold: 2.8249682811011914\n",
      "MAE for this fold: 2.814930391837997\n",
      "MAE for this fold: 2.81335782161276\n",
      "MAE for this fold: 2.8092082567323153\n",
      "MAE for this fold: 2.8295350483578\n",
      "MAE for this fold: 2.8119301966516437\n",
      "MAE for this fold: 2.8212127127769056\n",
      "MAE for this fold: 2.817554941246961\n",
      "MAE for this fold: 2.8095714221765045\n",
      "\n",
      "Final MAE on test set: 2.8178609466498625\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':4000,\n",
    "          'max_depth': 35,\n",
    "          'learning_rate': 0.005,\n",
    "          'colsample_bytree':0.80,\n",
    "          'gamma':10,\n",
    "          'reg_alpha':0.8,\n",
    "          'reg_lambda':0.1,\n",
    "          'objective': 'reg:squarederror',\n",
    "          'tree_method': 'hist',\n",
    "          'n_jobs':-1\n",
    "}\n",
    "models=[]\n",
    "\n",
    "num_folds = 15\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    models.append(model)\n",
    "\n",
    "    val_preds = model.predict(X_val_fold)\n",
    "\n",
    "    fold_mae = mean_absolute_error(y_val_fold, val_preds)\n",
    "    print(f'MAE for this fold: {fold_mae}')\n",
    "\n",
    "    test_fold_preds = model.predict(X_test)\n",
    "    test_predictions.append(test_fold_preds)\n",
    "\n",
    "final_test_predictions = np.mean(np.array(test_predictions), axis=0)\n",
    "\n",
    "final_mae = mean_absolute_error(y_test, final_test_predictions)\n",
    "print(f'\\nFinal MAE on test set: {final_mae}')\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "for model in models:\n",
    "    test_fold_preds = model.predict(data_test.drop(columns=\"ID\"))\n",
    "    test_predictions.append(test_fold_preds)\n",
    "\n",
    "data_test[\"Ewltp (g/km)\"] = np.mean(np.array(test_predictions), axis=0)\n",
    "\n",
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"results/new_kf15_xgb.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
