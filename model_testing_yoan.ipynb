{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonctions import Dataset\n",
    "from src.preprocessing import display_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=Dataset(\"data/train.csv\")\n",
    "data_train=train.load_data()\n",
    "test=Dataset(\"data/test.csv\")\n",
    "data_test=test.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonctions import Preprocessor,TrainPreprocessor,TestPreprocessor\n",
    "train_preprocessor=TrainPreprocessor(data_train)\n",
    "test_preprocessor=TestPreprocessor(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_continues=[\"Fuel consumption \",\"Electric range (km)\",\"ec (cm3)\",\"z (Wh/km)\",\"W (mm)\"]\n",
    "\n",
    "for col in variables_continues:\n",
    "    train_preprocessor.outlier_detection(col)\n",
    "    test_preprocessor.outlier_detection(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessor.fill_fuel_consumption()\n",
    "train_preprocessor.fill_electric_range()\n",
    "train_preprocessor.fill_engine_capacity()\n",
    "train_preprocessor.fill_electric_consumption()\n",
    "train_preprocessor.fill_category_type()\n",
    "train_preprocessor.fill_wheel_base()\n",
    "train_preprocessor.fill_At_1()\n",
    "train_preprocessor.fill_At_2()\n",
    "train_preprocessor.fill_mass()\n",
    "train_preprocessor.fill_engine_power()\n",
    "train_preprocessor.encode_country()\n",
    "train_preprocessor.encode_manufacture_pooling()\n",
    "train_preprocessor.last_step()\n",
    "\n",
    "test_preprocessor.fill_fuel_consumption()\n",
    "test_preprocessor.fill_electric_range()\n",
    "test_preprocessor.fill_engine_capacity()\n",
    "test_preprocessor.fill_electric_consumption()\n",
    "test_preprocessor.fill_category_type()\n",
    "test_preprocessor.fill_wheel_base()\n",
    "test_preprocessor.fill_At_1()\n",
    "test_preprocessor.fill_At_2()\n",
    "test_preprocessor.fill_mass()\n",
    "test_preprocessor.fill_engine_power()\n",
    "test_preprocessor.encode_country()\n",
    "test_preprocessor.encode_manufacture_pooling()\n",
    "test_preprocessor.last_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = train_preprocessor.encode_that_var(\"Ct\")\n",
    "data_train = train_preprocessor.encode_that_var(\"Cr\")\n",
    "data_test = test_preprocessor.encode_that_var(\"Ct\")\n",
    "data_test = test_preprocessor.encode_that_var(\"Cr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conforme(df):\n",
    "    df['conforme'] = df['Tan'].isna()\n",
    "    df['conforme'] = df['conforme'].apply(lambda x: 1 if x==False else 0)\n",
    "    df.drop(columns='Tan', inplace=True)\n",
    "    pass\n",
    "def compute_surface(obs):\n",
    "    max_largeur= max(obs['At1 (mm)'], obs['At2 (mm)'])\n",
    "    return obs['W (mm)']*obs['At1 (mm)'] if max_largeur == obs['At1 (mm)'] else obs['W (mm)'] * obs['At2 (mm)']\n",
    "\n",
    "def create_surface(df):\n",
    "    df['surface']= df.apply(compute_surface, axis=1)\n",
    "    pass\n",
    "\n",
    "def group_fuel_types(category: str):\n",
    "    if category in ['PETROL/ELECTRIC', 'DIESEL/ELECTRIC']:\n",
    "        return \"HYBRID\"\n",
    "    elif category in ['NG-BIOMETHANE', 'HYDROGEN', 'NG','E85']:\n",
    "        return \"BIO-FUEL\"\n",
    "    elif category in ['PETROL','LPG'] :\n",
    "        return 'PETROL'\n",
    "    else:\n",
    "        return category\n",
    "def create_carburant(df):\n",
    "    df['carburant']= df['Ft'].apply(group_fuel_types)\n",
    "    df.drop(columns='Ft',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_conforme(data_train)\n",
    "create_surface(data_train)\n",
    "create_carburant(data_train)\n",
    "\n",
    "create_conforme(data_test)\n",
    "create_surface(data_test)\n",
    "create_carburant(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = train_preprocessor.encode_that_var(\"carburant\")\n",
    "data_test = test_preprocessor.encode_that_var(\"carburant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_this_cuz_no_use=['VFN', 'Mh', 'Man', 'T', 'Mk', 'Cn','Mt']\n",
    "drop_this_cuz_personnal_choice = ['W (mm)', 'At1 (mm)', 'At2 (mm)','Fm','Erwltp (g/km)']\n",
    "\n",
    "data_train.drop(columns=drop_this_cuz_no_use, inplace=True)\n",
    "data_test.drop(columns=drop_this_cuz_no_use, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(columns='ID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from src.preprocessing import display_missing_values\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (numerical)\n",
    "No drop dupplicates, only keep numerical cols\n",
    "\n",
    "MAE: 3.2843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_keep = ['m (kg)', 'Ewltp (g/km)', 'W (mm)', 'At1 (mm)', 'At2 (mm)', 'ec (cm3)', 'ep (KW)', 'z (Wh/km)', 'Fuel consumption ', 'Electric range (km)']\n",
    "\n",
    "train, test = train_test_split(data_train[data_train.columns.intersection(columns_to_keep)], test_size=0.33, random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"Ewltp (g/km)\"]), train[\"Ewltp (g/km)\"]\n",
    "X_test, y_test = test.drop(columns=[\"Ewltp (g/km)\"]), test[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 3.2811834066371595\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Ewltp (g/km)\"] = random_forest.predict(data_test[data_test.columns.intersection(columns_to_keep)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"data/reg_rf_numerical_no_drop_dups.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF numerical (new set of predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_keep = ['m (kg)', 'Ewltp (g/km)', 'W (mm)', 'At1 (mm)', 'At2 (mm)', 'ec (cm3)', 'ep (KW)', 'z (Wh/km)', 'Fuel consumption ']\n",
    "\n",
    "train, test = train_test_split(data_train[data_train.columns.intersection(columns_to_keep)], test_size=0.33, random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"Ewltp (g/km)\"]), train[\"Ewltp (g/km)\"]\n",
    "X_test, y_test = test.drop(columns=[\"Ewltp (g/km)\"]), test[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 3.314147394462553\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Ewltp (g/km)\"] = random_forest.predict(data_test[data_test.columns.intersection(columns_to_keep)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"data/reg_rf_num_dups_no_e_range.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF outliers numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_keep = ['m (kg)', 'Ewltp (g/km)', 'W (mm)', 'At1 (mm)', 'At2 (mm)', 'ec (cm3)', 'ep (KW)', 'z (Wh/km)', 'Fuel consumption ', 'Electric range (km)']\n",
    "\n",
    "train, test = train_test_split(data_train[data_train.columns.intersection(columns_to_keep)], test_size=0.33, random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"Ewltp (g/km)\"]), train[\"Ewltp (g/km)\"]\n",
    "X_test, y_test = test.drop(columns=[\"Ewltp (g/km)\"]), test[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 3.2811834066371603\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Ewltp (g/km)\"] = random_forest.predict(data_test[data_test.columns.intersection(columns_to_keep)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"data/reg_rf_outlier.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF outliers numerical + country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_keep = ['m (kg)', 'Ewltp (g/km)', 'W (mm)', 'At1 (mm)',\n",
    "                    'At2 (mm)', 'ec (cm3)', 'ep (KW)', 'z (Wh/km)',\n",
    "                      'Fuel consumption ', 'Electric range (km)','Country']\n",
    "\n",
    "train, test = train_test_split(data_train[data_train.columns.intersection(columns_to_keep)], test_size=0.33, random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"Ewltp (g/km)\"]), train[\"Ewltp (g/km)\"]\n",
    "X_test, y_test = test.drop(columns=[\"Ewltp (g/km)\"]), test[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 3.185450881133795\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Ewltp (g/km)\"] = random_forest.predict(data_test[data_test.columns.intersection(columns_to_keep)])\n",
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"data/reg_rf_country.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### little test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_keep = ['m (kg)', 'Ewltp (g/km)', 'W (mm)', 'At1 (mm)',\n",
    "                    'At2 (mm)', 'ec (cm3)', 'ep (KW)', 'z (Wh/km)',\n",
    "                      'Fuel consumption ', 'Electric range (km)','Country']\n",
    "\n",
    "train, test = train_test_split(data_train[data_train.columns.intersection(columns_to_keep)], test_size=0.33, random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"Ewltp (g/km)\"]), train[\"Ewltp (g/km)\"]\n",
    "X_test, y_test = test.drop(columns=[\"Ewltp (g/km)\"]), test[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\model_testing_yoan.ipynb Cellule 35\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yoanj/Documents/M2S1/Projet_Mining/model_testing_yoan.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m random_forest \u001b[39m=\u001b[39m RandomForestRegressor(criterion\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mabsolute_error\u001b[39m\u001b[39m\"\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yoanj/Documents/M2S1/Projet_Mining/model_testing_yoan.ipynb#X62sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m random_forest\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yoanj/Documents/M2S1/Projet_Mining/model_testing_yoan.ipynb#X62sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_pred \u001b[39m=\u001b[39m random_forest\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yoanj/Documents/M2S1/Projet_Mining/model_testing_yoan.ipynb#X62sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m mae \u001b[39m=\u001b[39m mean_absolute_error(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(criterion=\"absolute_error\", random_state=42, n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Ewltp (g/km)\"] = random_forest.predict(data_test[data_test.columns.intersection(columns_to_keep)])\n",
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"data/reg_rf_outlier_country.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF outliers numerical + Country + Mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_keep = ['m (kg)','Mp', 'Ewltp (g/km)', \n",
    "                   'W (mm)', 'At1 (mm)', 'At2 (mm)',\n",
    "                     'ec (cm3)', 'ep (KW)', 'z (Wh/km)', \n",
    "                     'Fuel consumption ', 'Electric range (km)','Country']\n",
    "\n",
    "train, test = train_test_split(data_train[data_train.columns.intersection(columns_to_keep)], test_size=0.33, random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"Ewltp (g/km)\"]), train[\"Ewltp (g/km)\"]\n",
    "X_test, y_test = test.drop(columns=[\"Ewltp (g/km)\"]), test[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 3.1826152819810107\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Ewltp (g/km)\"] = random_forest.predict(data_test[data_test.columns.intersection(columns_to_keep)])\n",
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"data/reg_rf_outlier_country_mp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF (numerical) + K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep_no_target = ['m (kg)', 'W (mm)', 'At1 (mm)',\n",
    "                    'At2 (mm)', 'ec (cm3)', 'ep (KW)', 'z (Wh/km)',\n",
    "                      'Fuel consumption ', 'Electric range (km)','Country']\n",
    "\n",
    "X_train = data_train[data_train.columns.intersection(columns_to_keep_no_target)]\n",
    "y_train= data_train[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\model_testing_yoan.ipynb Cellule 35\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yoanj/Documents/M2S1/Projet_Mining/model_testing_yoan.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m y_train_fold, y_val_fold \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39miloc[train_index], y_train\u001b[39m.\u001b[39miloc[test_index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yoanj/Documents/M2S1/Projet_Mining/model_testing_yoan.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Entraînez le modèle sur X_train_fold et y_train_fold\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yoanj/Documents/M2S1/Projet_Mining/model_testing_yoan.ipynb#X42sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_fold, y_train_fold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yoanj/Documents/M2S1/Projet_Mining/model_testing_yoan.ipynb#X42sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Évaluez le modèle sur X_val_fold (vous pouvez utiliser la métrique de votre choix, par exemple MAE)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yoanj/Documents/M2S1/Projet_Mining/model_testing_yoan.ipynb#X42sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val_fold)\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "k_folds = 3\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Créez des listes pour stocker les modèles et les scores\n",
    "models = []\n",
    "scores = []\n",
    "\n",
    "# Effectuez la validation croisée\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    # Entraînez le modèle sur X_train_fold et y_train_fold\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Évaluez le modèle sur X_val_fold (vous pouvez utiliser la métrique de votre choix, par exemple MAE)\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "    mae = mean_absolute_error(y_val_fold, y_pred)\n",
    "    \n",
    "    # Stockez le modèle et le score\n",
    "    models.append(model)\n",
    "    scores.append(mae)\n",
    "\n",
    "# Affichez les scores MAE pour chaque pli\n",
    "for i, mae in enumerate(scores):\n",
    "    print(f\"Fold {i + 1} MAE: {mae}\")\n",
    "\n",
    "# Calculez la moyenne des scores MAE\n",
    "average_mae = sum(scores) / k_folds\n",
    "print(f\"Average MAE: {average_mae}\")\n",
    "\n",
    "best_model_index = scores.index(min(scores))\n",
    "best_model = models[best_model_index]\n",
    "\n",
    "print(f\"min MAE: {min(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Ewltp (g/km)\"] = best_model.predict(data_test.drop(columns='ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"data/reg_rf_numerical_kf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 5073004\n",
      "Taille de l'ensemble de validation : 1249322\n",
      "Taille de l'ensemble de test : 1249323\n"
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['m (kg)','Mp', 'Ewltp (g/km)', \n",
    "                   'W (mm)', 'At1 (mm)', 'At2 (mm)',\n",
    "                     'ec (cm3)', 'ep (KW)', 'z (Wh/km)', \n",
    "                     'Fuel consumption ', 'Electric range (km)','Country']\n",
    "train_data, rest_data = train_test_split(data_train[data_train.columns.intersection(columns_to_keep)], test_size=0.33, random_state=42)\n",
    "\n",
    "validation_data, test_data = train_test_split(rest_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vérifiez les tailles des ensembles\n",
    "print(\"Taille de l'ensemble d'entraînement :\", len(train_data))\n",
    "print(\"Taille de l'ensemble de validation :\", len(validation_data))\n",
    "print(\"Taille de l'ensemble de test :\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres : {'max_depth': 10, 'n_estimators': 150}\n",
      "MAE sur l'ensemble de test avec le meilleur modèle : 10.80078252858729\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Divisez les ensembles en caractéristiques (X) et cible (y)\n",
    "X_train, y_train = train_data.drop(columns=[\"Ewltp (g/km)\"]), train_data[\"Ewltp (g/km)\"]\n",
    "X_val, y_val = validation_data.drop(columns=[\"Ewltp (g/km)\"]), validation_data[\"Ewltp (g/km)\"]\n",
    "X_test, y_test = test_data.drop(columns=[\"Ewltp (g/km)\"]), test_data[\"Ewltp (g/km)\"]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 7, 10],\n",
    "}\n",
    "\n",
    "# Créez votre modèle\n",
    "base_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Utilisez GridSearchCV pour la recherche sur grille avec validation croisée\n",
    "grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid, scoring='neg_mean_absolute_error', cv=3)\n",
    "grid_search.fit(X_val, y_val)\n",
    "\n",
    "# Affichez les meilleurs hyperparamètres trouvés\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Meilleurs hyperparamètres :\", best_params)\n",
    "\n",
    "# Utilisez le meilleur modèle trouvé sur l'ensemble de test\n",
    "best_model = grid_search.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "print(\"MAE sur l'ensemble de test avec le meilleur modèle :\", mae_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF with test_fonctions script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_fonctions import Dataset\n",
    "from src.preprocessing import display_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=Dataset(\"data/train.csv\")\n",
    "data_train=train.load_data()\n",
    "test=Dataset(\"data/test.csv\")\n",
    "data_test=test.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_fonctions import Preprocessor,TrainPreprocessor,TestPreprocessor\n",
    "train_preprocessor=TrainPreprocessor(data_train)\n",
    "test_preprocessor=TestPreprocessor(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_continues=[\"Fuel consumption \",\"Electric range (km)\",\"ec (cm3)\",\"z (Wh/km)\",\"W (mm)\",\"Mt\"]\n",
    "\n",
    "for col in variables_continues:\n",
    "    train_preprocessor.outlier_detection(col)\n",
    "    test_preprocessor.outlier_detection(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessor.fill_fuel_consumption()\n",
    "train_preprocessor.fill_electric_range()\n",
    "train_preprocessor.fill_engine_capacity()\n",
    "train_preprocessor.fill_electric_consumption()\n",
    "train_preprocessor.fill_category_type()\n",
    "train_preprocessor.fill_wheel_base()\n",
    "train_preprocessor.fill_At_1()\n",
    "train_preprocessor.fill_At_2()\n",
    "train_preprocessor.fill_mass()\n",
    "train_preprocessor.fill_test_mass()\n",
    "train_preprocessor.fill_fuel_mode()\n",
    "train_preprocessor.fill_engine_power()\n",
    "train_preprocessor.encode_country()\n",
    "train_preprocessor.encode_manufacture_pooling()\n",
    "train_preprocessor.encode_fuel_mode()\n",
    "train_preprocessor.encode_fuel_type()\n",
    "train_preprocessor.last_step()\n",
    "\n",
    "test_preprocessor.fill_fuel_consumption()\n",
    "test_preprocessor.fill_electric_range()\n",
    "test_preprocessor.fill_engine_capacity()\n",
    "test_preprocessor.fill_electric_consumption()\n",
    "test_preprocessor.fill_category_type()\n",
    "test_preprocessor.fill_wheel_base()\n",
    "test_preprocessor.fill_At_1()\n",
    "test_preprocessor.fill_At_2()\n",
    "test_preprocessor.fill_mass()\n",
    "test_preprocessor.fill_test_mass()\n",
    "test_preprocessor.fill_fuel_mode()\n",
    "test_preprocessor.fill_engine_power()\n",
    "test_preprocessor.encode_country()\n",
    "test_preprocessor.encode_manufacture_pooling()\n",
    "test_preprocessor.encode_fuel_mode()\n",
    "test_preprocessor.encode_fuel_type()\n",
    "test_preprocessor.last_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conforme(df):\n",
    "    df['conforme'] = df['Tan'].isna()\n",
    "    df['conforme'] = df['conforme'].apply(lambda x: 1 if x==False else 0)\n",
    "    df.drop(columns='Tan', inplace=True)\n",
    "    pass\n",
    "def compute_surface(obs):\n",
    "    max_largeur= max(obs['At1 (mm)'], obs['At2 (mm)'])\n",
    "    return obs['W (mm)']*obs['At1 (mm)'] if max_largeur == obs['At1 (mm)'] else obs['W (mm)'] * obs['At2 (mm)']\n",
    "\n",
    "def create_surface(df):\n",
    "    df['surface']= df.apply(compute_surface, axis=1)\n",
    "    pass\n",
    "\n",
    "create_conforme(data_train)\n",
    "create_surface(data_train)\n",
    "\n",
    "create_conforme(data_test)\n",
    "create_surface(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_this_cuz_no_use=['VFN', 'Mh', 'Man', 'T', 'Mk', 'Cn']\n",
    "# drop_this_cuz_personnal_choice = ['W (mm)', 'At1 (mm)', 'At2 (mm)','Fm','Erwltp (g/km)']\n",
    "\n",
    "data_train.drop(columns=drop_this_cuz_no_use, inplace=True)\n",
    "data_test.drop(columns=drop_this_cuz_no_use, inplace=True)\n",
    "\n",
    "data_train.drop(columns='ID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from src.preprocessing import display_missing_values\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(columns=['Ct','Cr','Erwltp (g/km)'], inplace=True)\n",
    "data_test.drop(columns=['Ct','Cr','Erwltp (g/km)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Mp', 'm (kg)', 'Mt', 'Ewltp (g/km)', 'W (mm)', 'At1 (mm)',\n",
       "       'At2 (mm)', 'Ft', 'Fm', 'ec (cm3)', 'ep (KW)', 'z (Wh/km)',\n",
       "       'Fuel consumption ', 'Electric range (km)', 'flag_Fuel consumption ',\n",
       "       'flag_Electric range (km)', 'flag_ec (cm3)', 'flag_z (Wh/km)',\n",
       "       'flag_W (mm)', 'flag_Mt', 'conforme', 'surface'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_train, test_size=0.33, random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"Ewltp (g/km)\"]), train[\"Ewltp (g/km)\"]\n",
    "X_test, y_test = test.drop(columns=[\"Ewltp (g/km)\"]), test[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 2.976801154055315\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"Ewltp (g/km)\"] = random_forest.predict(data_test.drop(columns='ID'))\n",
    "data_test[[\"ID\",\"Ewltp (g/km)\"]].to_csv(\"data/rf_num_and_cat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Mp</th>\n",
       "      <th>m (kg)</th>\n",
       "      <th>Ewltp (g/km)</th>\n",
       "      <th>W (mm)</th>\n",
       "      <th>At1 (mm)</th>\n",
       "      <th>At2 (mm)</th>\n",
       "      <th>Ft</th>\n",
       "      <th>Fm</th>\n",
       "      <th>ec (cm3)</th>\n",
       "      <th>ep (KW)</th>\n",
       "      <th>z (Wh/km)</th>\n",
       "      <th>Fuel consumption</th>\n",
       "      <th>Electric range (km)</th>\n",
       "      <th>flag_Fuel consumption</th>\n",
       "      <th>flag_Electric range (km)</th>\n",
       "      <th>flag_ec (cm3)</th>\n",
       "      <th>flag_z (Wh/km)</th>\n",
       "      <th>flag_W (mm)</th>\n",
       "      <th>flag_Mt</th>\n",
       "      <th>conforme</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1387.00</td>\n",
       "      <td>401.05</td>\n",
       "      <td>2700.00</td>\n",
       "      <td>1571.00</td>\n",
       "      <td>1576.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>999.00</td>\n",
       "      <td>92.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4255200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1172.00</td>\n",
       "      <td>394.68</td>\n",
       "      <td>2552.00</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>1483.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>999.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3828000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1204.00</td>\n",
       "      <td>398.56</td>\n",
       "      <td>2552.00</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>1483.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>999.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3828000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1438.00</td>\n",
       "      <td>479.47</td>\n",
       "      <td>2650.00</td>\n",
       "      <td>1555.00</td>\n",
       "      <td>1563.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1591.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4141950.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1207.00</td>\n",
       "      <td>421.85</td>\n",
       "      <td>2552.00</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>1483.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>999.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3828000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Mp  m (kg)  Ewltp (g/km)  W (mm)  At1 (mm)  At2 (mm)   Ft   Fm  \\\n",
       "0        5   1 1387.00        401.05 2700.00   1571.00   1576.00 8.00 3.00   \n",
       "1       10  10 1172.00        394.68 2552.00   1500.00   1483.00 8.00 4.00   \n",
       "2       10  10 1204.00        398.56 2552.00   1500.00   1483.00 8.00 4.00   \n",
       "3        5   3 1438.00        479.47 2650.00   1555.00   1563.00 8.00 4.00   \n",
       "4       10  10 1207.00        421.85 2552.00   1500.00   1483.00 8.00 4.00   \n",
       "\n",
       "   ec (cm3)  ep (KW)  z (Wh/km)  Fuel consumption   Electric range (km)  \\\n",
       "0    999.00    92.00       0.00               5.60                 0.00   \n",
       "1    999.00    70.00       0.00               5.50                 0.00   \n",
       "2    999.00    70.00       0.00               5.60                 0.00   \n",
       "3   1591.00   150.00       0.00               6.80                 0.00   \n",
       "4    999.00    81.00       0.00               5.90                 0.00   \n",
       "\n",
       "   flag_Fuel consumption   flag_Electric range (km)  flag_ec (cm3)  \\\n",
       "0                       0                         0              0   \n",
       "1                       0                         0              0   \n",
       "2                       0                         0              0   \n",
       "3                       0                         0              0   \n",
       "4                       0                         0              0   \n",
       "\n",
       "   flag_z (Wh/km)  flag_W (mm)  flag_Mt  conforme    surface  \n",
       "0               0            0        0         1 4255200.00  \n",
       "1               0            0        0         1 3828000.00  \n",
       "2               0            0        0         1 3828000.00  \n",
       "3               0            0        0         1 4141950.00  \n",
       "4               0            0        0         1 3828000.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_train,test_size=0.33,random_state=42)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True ) #car ça fout la merde dans l'index\n",
    "test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "X_train, y_train =train.drop(columns=[\"Ewltp (g/km)\"]), train[\"Ewltp (g/km)\"]\n",
    "X_test, y_test =test.drop(columns=[\"Ewltp (g/km)\"]), test[\"Ewltp (g/km)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres : {'n_jobs': -1, 'n_estimators': 300, 'min_child_weight': 2, 'max_depth': 5, 'learning_rate': 0.2}\n",
      "Mean Absolute Error (MAE): 6.035682412861069\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Créez un modèle XGBoost\n",
    "xgb_model = XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "# Liste des hyperparamètres à régler et leurs plages de valeurs\n",
    "param_dist = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'n_jobs':[-1,-1,-1]\n",
    "}\n",
    "\n",
    "# Recherche aléatoire des hyperparamètres\n",
    "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=10, cv=5, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Exécutez la recherche aléatoire sur les données d'entraînement\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenez les meilleurs hyperparamètres\n",
    "best_params = random_search.best_params_\n",
    "print(\"Meilleurs hyperparamètres :\", best_params)\n",
    "\n",
    "# Utilisez les meilleurs hyperparamètres pour entraîner le modèle final\n",
    "best_xgb_model = XGBRegressor(objective=\"reg:squarederror\", random_state=42, **best_params)\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred =best_xgb_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.848606144154054\n"
     ]
    }
   ],
   "source": [
    "hist_gradient_boosting = HistGradientBoostingRegressor(interaction_cst=\"pairwise\",warm_start=True,\n",
    "                                                        learning_rate=0.3, random_state=42,\n",
    "                                                        categorical_features=['Country', 'Mp','Ft'])\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "hist_gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = hist_gradient_boosting.predict(X_test)\n",
    "\n",
    "# Calculer la MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data_train.drop(columns='Ewltp (g/km)'), data_train['Ewltp (g/km)']\n",
    "                                                    , test_size=0.33, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yoanj\\Documents\\M2S1\\Projet_Mining\\.venv_mining\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=HistGradientBoostingRegressor(random_state=42),\n",
       "                   param_distributions={&#x27;l2_regularization&#x27;: [0.0, 0.1, 0.2,\n",
       "                                                              0.4, 0.6, 0.8],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.1, 0.2, 0.3,\n",
       "                                                          0.8, 0.9],\n",
       "                                        &#x27;max_depth&#x27;: [3, 5, 7, 10, 12, 20],\n",
       "                                        &#x27;max_iter&#x27;: [100, 200, 300, 400, 500,\n",
       "                                                     600],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6, 7, 9]},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=HistGradientBoostingRegressor(random_state=42),\n",
       "                   param_distributions={&#x27;l2_regularization&#x27;: [0.0, 0.1, 0.2,\n",
       "                                                              0.4, 0.6, 0.8],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.1, 0.2, 0.3,\n",
       "                                                          0.8, 0.9],\n",
       "                                        &#x27;max_depth&#x27;: [3, 5, 7, 10, 12, 20],\n",
       "                                        &#x27;max_iter&#x27;: [100, 200, 300, 400, 500,\n",
       "                                                     600],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4, 6, 7, 9]},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=HistGradientBoostingRegressor(random_state=42),\n",
       "                   param_distributions={'l2_regularization': [0.0, 0.1, 0.2,\n",
       "                                                              0.4, 0.6, 0.8],\n",
       "                                        'learning_rate': [0.01, 0.1, 0.2, 0.3,\n",
       "                                                          0.8, 0.9],\n",
       "                                        'max_depth': [3, 5, 7, 10, 12, 20],\n",
       "                                        'max_iter': [100, 200, 300, 400, 500,\n",
       "                                                     600],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 7, 9]},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# Définir la grille des hyperparamètres\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2,0.3,0.8,0.9],\n",
    "    'max_depth': [3, 5, 7,10,12,20],\n",
    "    'max_iter': [100, 200, 300,400,500,600],\n",
    "    'min_samples_leaf': [1, 2, 4,6,7,9],\n",
    "    'l2_regularization': [0.0, 0.1, 0.2,0.4,0.6,0.8]\n",
    "}\n",
    "\n",
    "# Initialiser le modèle\n",
    "hgb_regressor = HistGradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Utiliser la recherche aléatoire\n",
    "random_search = RandomizedSearchCV(hgb_regressor, param_distributions=param_grid, n_iter=10, cv=3, scoring='neg_mean_absolute_error', random_state=42)\n",
    "\n",
    "# Exécuter la recherche\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 4.0602364248951\n"
     ]
    }
   ],
   "source": [
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Calculer la MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 4,\n",
       " 'max_iter': 600,\n",
       " 'max_depth': 20,\n",
       " 'learning_rate': 0.3,\n",
       " 'l2_regularization': 0.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
